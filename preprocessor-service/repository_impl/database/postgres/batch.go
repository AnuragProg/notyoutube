// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.27.0
// source: batch.go

package postgres

import (
	"context"
	"errors"

	"github.com/jackc/pgx/v5"
	"github.com/jackc/pgx/v5/pgtype"
)

var (
	ErrBatchAlreadyClosed = errors.New("batch already closed")
)

const createDependencies = `-- name: CreateDependencies :batchexec
INSERT INTO dependencies(id, dag_id)
VALUES ($1, $2)
`

type CreateDependenciesBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type CreateDependenciesParams struct {
	ID    pgtype.UUID `json:"id"`
	DagID pgtype.UUID `json:"dag_id"`
}

func (q *Queries) CreateDependencies(ctx context.Context, arg []CreateDependenciesParams) *CreateDependenciesBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.DagID,
		}
		batch.Queue(createDependencies, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CreateDependenciesBatchResults{br, len(arg), false}
}

func (b *CreateDependenciesBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *CreateDependenciesBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const createDependencySources = `-- name: CreateDependencySources :batchexec
INSERT INTO dependency_sources(id, dag_id, dependency_id, source_id)
VALUES ($1, $2, $3, $4)
`

type CreateDependencySourcesBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type CreateDependencySourcesParams struct {
	ID           pgtype.UUID `json:"id"`
	DagID        pgtype.UUID `json:"dag_id"`
	DependencyID pgtype.UUID `json:"dependency_id"`
	SourceID     pgtype.UUID `json:"source_id"`
}

func (q *Queries) CreateDependencySources(ctx context.Context, arg []CreateDependencySourcesParams) *CreateDependencySourcesBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.DagID,
			a.DependencyID,
			a.SourceID,
		}
		batch.Queue(createDependencySources, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CreateDependencySourcesBatchResults{br, len(arg), false}
}

func (b *CreateDependencySourcesBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *CreateDependencySourcesBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const createDependencyTargets = `-- name: CreateDependencyTargets :batchexec
INSERT INTO dependency_targets(id, dag_id, dependency_id, target_id)
VALUES ($1, $2, $3, $4)
`

type CreateDependencyTargetsBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type CreateDependencyTargetsParams struct {
	ID           pgtype.UUID `json:"id"`
	DagID        pgtype.UUID `json:"dag_id"`
	DependencyID pgtype.UUID `json:"dependency_id"`
	TargetID     pgtype.UUID `json:"target_id"`
}

func (q *Queries) CreateDependencyTargets(ctx context.Context, arg []CreateDependencyTargetsParams) *CreateDependencyTargetsBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.DagID,
			a.DependencyID,
			a.TargetID,
		}
		batch.Queue(createDependencyTargets, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CreateDependencyTargetsBatchResults{br, len(arg), false}
}

func (b *CreateDependencyTargetsBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *CreateDependencyTargetsBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const createWorker = `-- name: CreateWorker :batchexec
INSERT INTO workers(id, dag_id, name, description, worker_type, worker_config)
VALUES ($1, $2, $3, $4, $5, $6)
`

type CreateWorkerBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type CreateWorkerParams struct {
	ID           pgtype.UUID `json:"id"`
	DagID        pgtype.UUID `json:"dag_id"`
	Name         string      `json:"name"`
	Description  pgtype.Text `json:"description"`
	WorkerType   WorkerType  `json:"worker_type"`
	WorkerConfig []byte      `json:"worker_config"`
}

func (q *Queries) CreateWorker(ctx context.Context, arg []CreateWorkerParams) *CreateWorkerBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.DagID,
			a.Name,
			a.Description,
			a.WorkerType,
			a.WorkerConfig,
		}
		batch.Queue(createWorker, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CreateWorkerBatchResults{br, len(arg), false}
}

func (b *CreateWorkerBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *CreateWorkerBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}
